{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6lSB7ufVyRP",
        "outputId": "289a7ef7-2a23-41b8-8fd6-fda2d53860a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.12.14)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.115.6 starlette-0.41.3\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.12.2)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn\n",
            "Successfully installed uvicorn-0.34.0\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=255317 sha256=bb1778d9c39618b2d722d556185a0e5676ffc0c2d29bbf05798cc28e269ea9b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Collecting pypi-json\n",
            "  Downloading pypi_json-0.4.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting apeye>=1.1.0 (from pypi-json)\n",
            "  Downloading apeye-1.4.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (24.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (2.32.3)\n",
            "Collecting apeye-core>=1.0.0b2 (from apeye>=1.1.0->pypi-json)\n",
            "  Downloading apeye_core-1.1.5-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting domdf-python-tools>=2.6.0 (from apeye>=1.1.0->pypi-json)\n",
            "  Downloading domdf_python_tools-3.9.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2024.12.14)\n",
            "Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (4.12.2)\n",
            "Downloading pypi_json-0.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading apeye-1.4.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apeye_core-1.1.5-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading domdf_python_tools-3.9.0-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: domdf-python-tools, apeye-core, apeye, pypi-json\n",
            "Successfully installed apeye-1.4.1 apeye-core-1.1.5 domdf-python-tools-3.9.0 pypi-json-0.4.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U accelerate\n",
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pickle5\n",
        "!pip install pydantic\n",
        "!pip install scikit-learn\n",
        "!pip install requests\n",
        "!pip install pypi-json\n",
        "!pip install pyngrok\n",
        "!pip install nest-asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1-rTTMoV4ss"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import pickle\n",
        "import json\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "ab43a09fbf204a69a492ea96580dc11c",
            "6be2209a18dc4fb1b29144fba1c2a46f",
            "70adcb5b999545589e929746bdf670b3",
            "11e48066763b4b528bb88dce95752c08",
            "0276bfc532bd417da76e54376e12815b",
            "a4295a9c63b74cc7a9303a5c763e2e59",
            "f86f3fe3d9544bd9b560a3c0f0b05f24",
            "f17574d04d2a4da6991ed5546b35ed10",
            "cc43eb3ba2f24f82a99bf05716db7959",
            "1bbbb6a899624958bee2135987eb9846",
            "0b3e47ded747436db1e9fa39cec29d3f",
            "254ff3154dd846229cf58634e0156a1d"
          ]
        },
        "id": "zCmWyCNNWXn1",
        "outputId": "c7b4ea39-9941-439a-e6c6-042d2622b6f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab43a09fbf204a69a492ea96580dc11c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6be2209a18dc4fb1b29144fba1c2a46f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70adcb5b999545589e929746bdf670b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11e48066763b4b528bb88dce95752c08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0276bfc532bd417da76e54376e12815b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4295a9c63b74cc7a9303a5c763e2e59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f86f3fe3d9544bd9b560a3c0f0b05f24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17574d04d2a4da6991ed5546b35ed10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc43eb3ba2f24f82a99bf05716db7959",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bbbb6a899624958bee2135987eb9846",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b3e47ded747436db1e9fa39cec29d3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.62M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "254ff3154dd846229cf58634e0156a1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Define the quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True\n",
        ")\n",
        "\n",
        "# Load the model with CPU offloading\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Sr33ja/kathavachak-7b\",\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Sr33ja/kathavachak-7b\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nEPOeYGekIEN"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# import io\n",
        "# from PIL import Image\n",
        "# from typing import List\n",
        "# from zipfile import ZipFile\n",
        "# from io import BytesIO\n",
        "# import base64\n",
        "# # API details\n",
        "# API_URL = \"https://api-inference.huggingface.co/models/ZB-Tech/Text-to-Image\"\n",
        "# headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "# # Function to query the API\n",
        "# def query(payload):\n",
        "#     response = requests.post(API_URL, headers=headers, json=payload)\n",
        "#     if response.status_code == 200:\n",
        "#         return response.content\n",
        "#     else:\n",
        "#         raise Exception(f\"API Error: {response.status_code} - {response.text}\")\n",
        "\n",
        "# # Function to generate and display multiple images\n",
        "# def generate_story_images(prompts: List[str]):\n",
        "#     images_base64 = []\n",
        "#     for idx, prompt in enumerate(prompts):\n",
        "#         # For illustration, we generate a simple image based on the prompt index\n",
        "#         img = Image.new(\"RGB\", (512, 512), color=(idx * 50, idx * 30, idx * 20))\n",
        "\n",
        "#         # Convert image to bytes and then base64\n",
        "#         img_bytes = io.BytesIO()\n",
        "#         img.save(img_bytes, format=\"PNG\")\n",
        "#         img_bytes.seek(0)\n",
        "\n",
        "#         encoded_image = base64.b64encode(img_bytes.getvalue()).decode(\"utf-8\")\n",
        "#         images_base64.append(encoded_image)\n",
        "\n",
        "#     return images_base64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2Znd6oqqV9DY"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import JSONResponse, FileResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import re\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# CORS Configuration\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"http://localhost:5173\"],  # Allow only your frontend origin\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],  # Allow all HTTP methods (GET, POST, etc.)\n",
        "    allow_headers=[\"*\"],  # Allow all headers\n",
        ")\n",
        "\n",
        "# Example story input model\n",
        "class StoryInput(BaseModel):\n",
        "    genre: str\n",
        "    title: str\n",
        "    plot: str\n",
        "\n",
        "from transformers import pipeline, logging\n",
        "\n",
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "\n",
        "# Initialize the text generation pipeline\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "# def extract_storyline(generated_text):\n",
        "#     # Extract prompts for the storyline (after \"Storyline Prompts for Illustration:\")\n",
        "#     if \"Storyline Prompts for Illustration:\" in generated_text:\n",
        "#         storyline_part = generated_text.split(\"Storyline Prompts for Illustration:\")[-1].strip()\n",
        "#         # Split by numbering and capture only the detailed descriptions\n",
        "#         descriptions = []\n",
        "#         for line in storyline_part.split(\"\\n\"):\n",
        "#             line = line.strip()\n",
        "#             if line and not line.startswith((\"1. [\", \"2. [\", \"3. [\")):\n",
        "#                 descriptions.append(line)\n",
        "#         return descriptions[:3]  # Ensure we only return the first three descriptions\n",
        "#     return []\n",
        "\n",
        "def extract_storyline(generated_text):\n",
        "    # Extract prompts for the storyline\n",
        "    if \"Storyline Prompts for Illustration:\" in generated_text:\n",
        "        storyline_part = generated_text.split(\"Storyline Prompts for Illustration:\")[-1].strip()\n",
        "        descriptions = []\n",
        "        lines = storyline_part.split(\"\\n\")\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "\n",
        "            # Ignore lines that only contain bracketed descriptions\n",
        "            if re.match(r\"^\\d+\\.\\s*\\[.*?\\]$\", line):\n",
        "                continue\n",
        "            # Ignore lines that match the instructional pattern\n",
        "            if re.match(r\"^\\d+\\.\\s*A vivid and very short description of.*?$\", line):\n",
        "                continue\n",
        "\n",
        "            # Match detailed descriptions (after the bracketed line)\n",
        "            if line and not (line.startswith((\"1. [\", \"2. [\", \"3. [\")) and re.match(r\"^\\d+\\.\\s*A vivid and very short description of.*?$\", line)):\n",
        "                descriptions.append(line)\n",
        "\n",
        "        return descriptions[:3]  # Return only the first three descriptions if available\n",
        "    return []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_instruction(text):\n",
        "    # Use regex to remove anything between <s>[INST] and [/INST] including those tags\n",
        "    cleaned_text = re.sub(r\"<s>\\[INST\\].*?\\[/INST\\]\", \"\", text, flags=re.DOTALL).strip()\n",
        "    return cleaned_text\n",
        "\n",
        "def extract_story(response: str) -> str:\n",
        "    \"\"\"\n",
        "    Removes the 'Storyline Prompts for Illustration' section and returns the cleaned story content.\n",
        "    \"\"\"\n",
        "    # Define the delimiter for storyline prompts\n",
        "    storyline_delimiter = \"Storyline Prompts for Illustration:\"\n",
        "    story_start = \"Story:\"  # Identify where the actual story begins\n",
        "\n",
        "    # Check if the storyline section exists in the response\n",
        "    if storyline_delimiter in response:\n",
        "        # Split into parts at the storyline section\n",
        "        parts = response.split(storyline_delimiter)\n",
        "        before_storyline = parts[0].strip()  # Content before storyline prompts\n",
        "        after_storyline = parts[1].strip() if len(parts) > 1 else \"\"\n",
        "\n",
        "        # If the actual story begins after the storyline section\n",
        "        if story_start in after_storyline:\n",
        "            # Extract everything from \"Story:\" onward\n",
        "            story_part = after_storyline.split(story_start, 1)[1].strip()\n",
        "            return f\"{before_storyline}\\n\\n{story_start}\\n\\n{story_part}\"\n",
        "\n",
        "        # If the \"Story:\" section isn't found, just return the before part\n",
        "        return before_storyline\n",
        "\n",
        "    # If no storyline section exists, return the entire response\n",
        "    return response.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.post(\"/story\")\n",
        "def chat_model1(input_params: StoryInput):\n",
        "    genre = input_params.genre\n",
        "    title = input_params.title\n",
        "    plot_details = input_params.plot\n",
        "    prompt = f\"\"\"\n",
        "    You are a creative and skilled storyteller. Based on the following inputs, generate a detailed, engaging, and well-structured story:\n",
        "\n",
        "    - *Genre*: {genre}\n",
        "    - *Story Title*: \"{title}\"\n",
        "    - *Plot Details*: {plot_details}\n",
        "\n",
        "    Guidelines:\n",
        "    1. Write a complete and engaging story with a *BEGINNING, **MIDDLE, and **END, adhering to the conventions of the **{genre}* genre.\n",
        "    2. Start with a compelling hook that captivates the reader, drawing inspiration from the title and plot details provided.\n",
        "    3. Develop a clear and cohesive narrative that incorporates the plot details naturally, ensuring all elements are interconnected and contribute to the story's progression.\n",
        "    4. Include vivid descriptions, relatable characters, dynamic settings, and natural dialogue that enrich the atmosphere and themes of the story.\n",
        "    5. Conclude with a thoughtful and satisfying resolution that ties up major narrative threads and aligns with the genre's tone and style.\n",
        "\n",
        "    After writing the story, create a section called Storyline Prompts for Illustration. In this section, identify *exactly three vivid and descriptive key scenes* from the story for illustration purposes. Each prompt should include:\n",
        "\n",
        "    - Specific details about the scene (characters, actions, emotions, and setting) to ensure accurate visualization.\n",
        "    - The sequence should align with the narrative progression of the story.\n",
        "\n",
        "    Example format for Storyline Prompts for Illustration:\n",
        "    1. [A vivid and very short description of the first key scene from the story, ensuring detail character features and settings are consistent with the described events.]\n",
        "    2. [A vivid and very short description of the second key scene from the story, ensuring detail character features and settings are consistent with the described events.]\n",
        "    3. [A vivid and very short description of the third key scene from the story, ensuring detail character features and settings are consistent with the described events.]\n",
        "    Important:\n",
        "    - Ensure the story is fully generated before creating the storyline prompts.\n",
        "    - Do not return only the plot or storyline prompts without completing the story first.\n",
        "\n",
        "    Now, generate the story followed by the Storyline Prompts for Illustration section:\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Generate the text using the defined prompt\n",
        "    result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "    response=result[0]['generated_text']\n",
        "    response=remove_instruction(response)\n",
        "    extracted_storyline = extract_storyline(response)\n",
        "    extracted_story=extract_story(response)\n",
        "    print(extracted_storyline)\n",
        "    print(response)\n",
        "    # images = generate_story_images(extracted_storyline)\n",
        "\n",
        "    return {\"story\": extracted_story, \"prompts\": extracted_storyline}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G4cU4XMSWDGK",
        "outputId": "5d03bf6f-8cdc-4555-b1ce-7e2f4ac7b408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "# Replace 'YOUR_AUTHTOKEN' with your actual ngrok authtoken\n",
        "ngrok.set_auth_token(\"2kJtvh8yyst09UD0GZ9CgMk0Lqb_64Y7ay7zmRjGFtF2bGMNV\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q8adTgBHWRZw",
        "outputId": "c603f0f6-c507-45ed-9bed-2a1d4165a56d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [280]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://de62-34-145-88-186.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFsVHBlyXFSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}